{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import time\n","import threading\n","import concurrent.futures\n","import json\n","import statistics\n","import random\n","import datetime\n","import pandas as pd\n","import numpy as np\n","from pydruid.db import connect\n","import json\n","import random\n","import os\n","\n","\n","conn = connect(host='localhost', port=8082, path='/druid/v2/sql/', scheme='http')\n","curs = conn.cursor()\n","\n","#CREAZIONE DEL FILE PER RACCOGLIERE I RISULTATI\n","data = {}\n","\n","for i in range(9):\n","    data[i] = {\n","        \"Times\": []\n","    }\n","\n","filename ='../stats/reduced_execution_times_parallel.json'\n","file_exceptions='../stats/exceptions.json'\n","\n","if not os.path.exists(filename):\n","    with open(filename, \"w\") as f:\n","        json.dump(data, f)\n","        print(f\"Il file {filename} è stato creato con successo!\")\n","else:\n","    print(f\"Il file {filename} esiste già!\")\n","\n","\n","with open(file_exceptions, 'w') as outfile:\n","    json.dump({}, outfile)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ops=[\"<\", \">\", \"=\"]\n","dimensions = {}\n","dimensions['princ']={}\n","dimensions['princ']['WARD'] = []\n","dimensions['princ']['DISTRICT'] = []\n","dimensions['sub']={}\n","dimensions['sub']['NEIGHBORHOOD_CLUSTER'] = []\n","dimensions['sub']['ANC'] = []\n","dimensions['sub']['BLOCK_GROUP'] = []\n","dimensions['sub']['VOTING_PRECINCT'] = []\n","dimensions['sub']['CENSUS_TRACT'] = []\n","\n","def get_random_pc():\n","    index_ns = np.random.randint(0, 1)\n","    index_ew = np.random.randint(0, 1)\n","    ns = [\"North\", \"South\"]\n","    ew = [\"East\", \"Weast\"]\n","    return ns[index_ns], ew[index_ew]\n","\n","def get_random_interval():\n","    timestamp_end = 1601159260\n","    timestamp_init = 631152000\n","    random_numbers = random.sample(range(timestamp_init, timestamp_end), 2)\n","    random_numbers.sort()\n","    date_init = datetime.datetime.fromtimestamp( random_numbers[0]).strftime('%Y-%m-%dT%H:%M:%S')\n","    date_end = datetime.datetime.fromtimestamp( random_numbers[1]).strftime('%Y-%m-%dT%H:%M:%S')\n","    return date_init, date_end\n","\n","def get_random_sing_dimension(cat):\n","    return random.choice(list(dimensions[cat].keys()))\n","\n","def get_random_mult_dimension(cat, n):\n","    indices = random.sample(list(dimensions[cat].keys()), n)\n","    return indices\n","\n","def get_random_value(index1, index2):\n","    return random.choice(dimensions[index1][index2])\n","\n","def get_random_year():\n","    return np.random.randint(1990, 2023)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for key in list(dimensions.keys()):\n","    for sub_key in list(dimensions[key].keys()):\n","        query = 'SELECT DISTINCT(\"{dim}\") FROM \"crimesOtt\"'.format(dim=sub_key)\n","        cur = curs.execute(query)\n","        res = [row[0] for row in cur.fetchall()]\n","        dimensions[key][sub_key] = res\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["reduced_queries=[]\n","#SELECTION QUERY \n","reduced_queries.append([0,\n","\"\"\"\n","SELECT SUM(\"count\") AS \"Count\"\n","FROM \"crimesOtt\"\n","WHERE \"NS\" = '{ns}' AND \"EW\" = '{ew}' \n","GROUP BY ()\n","\n","\"\"\"\n","])\n","\n","reduced_queries.append([1,\"\"\"\n","SELECT \n","  \"{dim_1}\", \n","  SUM(\"count\") AS \"total_crimes\",\n","  CONCAT(ROUND(SUM(CAST(\"count\" AS NUMERIC(10,2)))*100/ (SELECT SUM(CAST(\"count\" AS NUMERIC(10,2))) FROM \"crimesOtt\"), 4), '%') AS \"rate\" \n","FROM \"crimesOtt\"\n","WHERE \"{dim_2}\" = '{value}' AND \"CRIMETYPE\" = '{type}' AND EXTRACT(YEAR FROM FLOOR(\"__time\" TO YEAR)) = {year} = '{year}'\n","GROUP BY 1\n","\"\"\"\n","])\n","\n","reduced_queries.append([2,\"\"\"\n","SELECT\n","  APPROX_COUNT_DISTINCT_DS_THETA(\"theta_PSA\") AS \"approx_count_psa\"\n","FROM \"crimesOtt\"\n","WHERE \"{dim}\" = '{value}' AND EXTRACT(YEAR FROM FLOOR(\"__time\" TO YEAR)) = {year}\n","\"\"\"\n","])\n","\n","reduced_queries.append([3,\"\"\"\n","SELECT\n","\"year1\",\n","\"{dim_1}\",\n","\"max_count\"\n","FROM(\n","  SELECT \"year1\", MAX(\"count1\") AS \"max_count\"\n","    FROM(\n","      SELECT \n","        EXTRACT(YEAR FROM FLOOR(\"__time\" TO YEAR)) AS \"year1\",\n","        \"{dim_1}\",\n","        SUM(\"count\") AS \"count1\"\n","      FROM \"crimesOtt\"\n","      GROUP BY 1, 2\n","    ) \n","    GROUP BY 1\n",") \n","LEFT JOIN \n","(\n","  SELECT \n","    EXTRACT(YEAR FROM FLOOR(\"__time\" TO YEAR)) AS \"year2\",\n","    \"{dim_1}\",\n","    SUM(\"count\") AS \"count2\"\n","  FROM \"crimesOtt\"\n","  GROUP BY 1, 2\n",")\n","ON \"year1\" = \"year2\" AND \"max_count\" = \"count2\"\n","\"\"\"\n","])\n","\n","reduced_queries.append([4,\"\"\"\n","WITH\n","crimes_dim1 AS (\n","SELECT\n","EXTRACT(\n","  YEAR FROM FLOOR(\"__time\" TO YEAR)) AS \"year\",\n","  \"{dim1}\",\n","  SUM(\"count\") AS \"count\"\n","  FROM \"crimesOtt\"\n","  GROUP BY 1, 2\n","),\n","crimes_dim2 AS (\n","SELECT\n","EXTRACT(\n","  YEAR FROM FLOOR(\"__time\" TO YEAR)) AS \"year\",\n","  \"{dim2}\",\n","  SUM(\"count\") AS \"count\"\n","  FROM \"crimesOtt\"\n","  GROUP BY 1, 2\n",")\n","\n","SELECT\n","t1.\"year\",\n","t1.\"{dim1}\",\n","t1.\"max_dim1_count\",\n","t2.\"{dim2}\",\n","t2.\"max_dim2_count\"\n","FROM\n","(\n","  SELECT\n","  a.\"year\",\n","  a.\"{dim1}\",\n","  a1.\"max_dim1_count\"\n","  FROM crimes_dim1 a\n","  INNER JOIN (\n","  SELECT\n","  \"year\",\n","  MAX(\"count\") AS \"max_dim1_count\"\n","  FROM crimes_dim1\n","  GROUP BY 1\n","  ) a1\n","  ON a.\"year\" = a1.\"year\" AND a.\"count\" = a1.\"max_dim1_count\"\n",") AS t1\n","LEFT JOIN(\n","  SELECT\n","  b.\"year\",\n","  b.\"{dim2}\",\n","  b1.\"max_dim2_count\"\n","  FROM crimes_dim2 b\n","  INNER JOIN (\n","  SELECT\n","  \"year\",\n","  MAX(\"count\") AS \"max_dim2_count\"\n","  FROM crimes_dim2\n","  GROUP BY 1\n","  ) b1\n","  ON b.\"year\" = b1.\"year\" AND b.\"count\" =  b1.\"max_dim2_count\"\n",") AS t2\n","ON t1.\"year\" = t2.\"year\"\n","\"\"\"\n","])\n","\n","reduced_queries.append([5,\"\"\"\n","SELECT\n","  APPROX_COUNT_DISTINCT_DS_THETA(\"theta_BLOCK\") AS \"approx_count_blocks\"\n","FROM \"crimesOtt\"\n","WHERE \"ANC\" = '{value_A}' AND \"NEIGHBORHOOD_CLUSTER\" = '{value_NC}' AND \"VOTING_PRECINCT\" = '{value_VP}' AND \"BLOCK_GROUP\" = '{value_BG}' AND \"CENSUS_TRACT\" = '{value_CT}' AND \"CRIMETYPE\" = '{value_C}' AND EXTRACT(YEAR FROM FLOOR(\"__time\" TO YEAR)) = {year}\n","\"\"\"\n","])\n","\n","reduced_queries.append([6,\"\"\"\n","SELECT\n","  APPROX_COUNT_DISTINCT_DS_THETA(\"theta_OFFENSE_TYPE\") AS \"different_offense_type\"\n","FROM \"crimesOtt\"\n","WHERE \"DISTRICT\"={value_dist} AND \"{dim}\" = '{value_dim}' \n","\"\"\"\n","])\n","\n","reduced_queries.append([7,\"\"\"\n","SELECT \n","  EXTRACT(MONTH FROM FLOOR(\"__time\" TO MONTH)) AS \"month\",\n","  ROUND(SUM(CAST(\"count\" AS NUMERIC(10,2)))*100/(SELECT COUNT(DISTINCT(EXTRACT(YEAR FROM FLOOR(\"__time\" TO YEAR)))) FROM \"crimesOtt\"))\n","FROM \"crimesOtt\"\n","WHERE \"{dim}\" = '{value}' AND \"CRIMETYPE\" = '{type}'\n","GROUP BY 1\n","\"\"\"])\n","\n","reduced_queries.append([8, \"\"\"\n","SELECT COUNT(*) \n","FROM \"crimesOtt\"\n","WHERE \"__time\" >= '{date_init}' AND \"__time\" < '{date_end}' AND '{dim}' = '{value}'\n","\"\"\"])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def build_query(index):\n","    query = reduced_queries[index]\n","    n_query = query[0]\n","    ex_query = query[1]\n","\n","    if n_query == 0:\n","        ns_, ew_ = get_random_pc()\n","        return ex_query.format(ns=ns_, ew=ew_)\n","    elif n_query == 1:\n","        dim1_= get_random_sing_dimension(\"sub\")\n","        dim2_= get_random_sing_dimension(\"princ\")\n","        value_= get_random_value(\"princ\", dim2_)\n","        crimetype  = random.choice([\"Violent\", \"Non-Violent\"])\n","        year_ = get_random_year()\n","        return ex_query.format(dim_1 = dim1_ , dim_2 = dim2_ , value = value_, type=crimetype, year=year_)\n","    elif n_query == 2:\n","        cat = random.choice([\"sub\", \"princ\"])\n","        dim_ = get_random_sing_dimension(cat) \n","        value_ = get_random_value(cat, dim_)\n","        year_ = get_random_year()\n","        return ex_query.format(dim=dim_, value=value_, year=year_)\n","    elif n_query == 3:\n","        cat = random.choice([\"sub\", \"princ\"])\n","        dim_ = get_random_sing_dimension(cat)\n","        return ex_query.format(dim_1=dim_)\n","    elif n_query == 4:\n","        cat = random.choice([\"sub\", \"princ\"])\n","        dims = get_random_mult_dimension(cat, 2)\n","        return ex_query.format(dim1=dims[0], dim2=dims[1])\n","    elif n_query == 5:\n","        value_A_ = get_random_value(\"sub\", \"ANC\") \n","        value_NC_ = get_random_value(\"sub\", \"NEIGHBORHOOD_CLUSTER\")\n","        value_VP_ = get_random_value(\"sub\", \"VOTING_PRECINCT\")\n","        value_BG_ = get_random_value(\"sub\", \"BLOCK_GROUP\")\n","        value_CT_ = get_random_value(\"sub\", \"CENSUS_TRACT\")\n","        value_C_ = np.random.choice([\"Violent\",\"Non-Violent\"])\n","        year_ = get_random_year()\n","        return ex_query.format(value_A=value_A_ , value_NC=value_NC_ , value_VP=value_VP_ , value_BG=value_BG_ , value_CT=value_CT_ , value_C=value_C_ , year=year_)\n","    \n","    elif n_query == 6:\n","        cat = random.choice([\"sub\", \"princ\"])\n","        dim_ = get_random_sing_dimension(cat)\n","        value_ = get_random_value(cat, dim_)\n","        value_dist_ = get_random_value(\"princ\", \"DISTRICT\")\n","        year_ = get_random_year()\n","        return ex_query.format(value_dist=value_dist_, dim=dim_, value_dim=value_, year=year_)\n","    elif n_query == 7:\n","        dim_=get_random_sing_dimension(\"princ\")\n","        value_=get_random_value(\"princ\", dim_)\n","        type_=np.random.choice([\"Violent\",\"Non-Violent\"])\n","        return ex_query.format(dim=dim_, value=value_, type=type_)\n","    elif n_query == 8:\n","        date_init_, date_end_ = get_random_interval()\n","        cat = random.choice([\"sub\", \"princ\"])\n","        dim_ = get_random_sing_dimension(cat)\n","        value_ = get_random_value(cat, dim_)\n","        return ex_query.format(date_init = date_init_, date_end = date_end_, dim=dim_, value=value_)\n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#FUNZIONI PER ESEGUIRE QUERY\n","def update_times(key, new_time, file):\n","    with open(file, 'r+') as file:\n","        data = json.load(file)\n","        data[key][\"Times\"].append(new_time)\n","        file.seek(0)\n","        json.dump(data, file, indent=4)\n","        file.truncate()\n","\n","def update_metrics(key, filename):\n","    with open(filename, 'r+') as file:\n","        data = json.load(file)\n","        execution_times = data[key][\"Times\"]\n","        mean = statistics.mean(execution_times)\n","        stdev = statistics.stdev(execution_times)\n","        data[key][\"Mean\"] = mean\n","        data[key][\"Stdev\"] = stdev\n","        file.seek(0)\n","        json.dump(data, file, indent=4)\n","        file.truncate()\n","\n","def execute_query(query):\n","    start_time = time.time()\n","    curs.execute(query)\n","    end_time = time.time()\n","    return (end_time-start_time)\n","\n","def execute_query_parallel(query, data):\n","    start_time = time.time()\n","    curs.execute(query[1])\n","    end_time = time.time()\n","    data[str(query[0])][\"Times\"].append(end_time-start_time)\n","    \n","\n","def get_times(file):\n","    with open(file, 'r+') as file:\n","        return json.load(file)\n","\n","def update_times(file, data):\n","    with open(file, 'r+') as file:\n","        file.seek(0)\n","        json.dump(data, file, indent=4)\n","        file.truncate()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dim_queries = 30000\n","cycle = 3000\n","list_time_sleep = [0.1, 0,2, 0.3]\n","list_num_threads = [9, 18, 27]\n","query_red=[]\n","for i in range(0, dim_queries):\n","    random.shuffle(reduced_queries)\n","    for query in reduced_queries:\n","        fquery = build_query(query[0])\n","        query_red.append([query[0], fquery])\n","random.shuffle(query_red)\n","data = get_times(filename)\n","with open(\"file.txt\", \"a\") as file:\n","    for i in range(0, cycle):\n","        with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n","            time_sleep=random.choice(list_time_sleep)\n","            num_threads=random.choice(list_num_threads)\n","            try:\n","                time.sleep(time_sleep)\n","                executor.submit(execute_query_parallel, query_red[i], data)\n","                \n","            except Exception as e:\n","                with open(file_exceptions, 'r+') as file:\n","                    data = json.load(file)\n","                    error = {}\n","                    error[\"datasource\"]=\"reduced\"\n","                    error[\"e\"]=str(e)\n","                    error[\"id\"]=query_red[i][0]\n","                    error[\"query\"]=query_red[i][1]\n","                    data[i] =error\n","                    file.seek(0)\n","                    json.dump(data, file, indent=1)\n","                    file.truncate()          \n","update_times(filename, data)\n"]}],"metadata":{"kernelspec":{"display_name":"code_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
